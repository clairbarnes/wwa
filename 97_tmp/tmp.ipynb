{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75254b6f-94c2-4b30-8951-fb25e1bb3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/home/clair/wwa'); from wwa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bac981e-9ea5-48d2-a09e-149ccd7230be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine cfgrib must be one of: ['netcdf4', 'scipy', 'rasterio', 'store']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madaptor.mars.internal-1671796225.7580643-1770-16-a3cee338-58d0-4bdd-b02a-9168a2a869be.grib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcfgrib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wwa/lib/python3.10/site-packages/xarray/backends/api.py:517\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     engine \u001b[38;5;241m=\u001b[39m plugins\u001b[38;5;241m.\u001b[39mguess_engine(filename_or_obj)\n\u001b[0;32m--> 517\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    520\u001b[0m     decode_cf,\n\u001b[1;32m    521\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    528\u001b[0m )\n\u001b[1;32m    530\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wwa/lib/python3.10/site-packages/xarray/backends/plugins.py:163\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    161\u001b[0m     engines \u001b[38;5;241m=\u001b[39m list_engines()\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[0;32m--> 163\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     backend \u001b[38;5;241m=\u001b[39m engines[engine]\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine cfgrib must be one of: ['netcdf4', 'scipy', 'rasterio', 'store']"
     ]
    }
   ],
   "source": [
    "xr.open_dataset(\"adaptor.mars.internal-1671796225.7580643-1770-16-a3cee338-58d0-4bdd-b02a-9168a2a869be.grib\", engine = \"cfgrib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027da86a-ecd0-44c5-a8f6-85fccc9717e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | os.PathLike | AbstractDataStore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'T_Engine'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'T_Chunks'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecode_cf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecode_times\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecode_timedelta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_cftime\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcat_characters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecode_coords\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Literal['coordinates', 'all'] | bool | None\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdrop_variables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | Iterable[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minline_array\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbackend_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dict[str, Any] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Open and decode a dataset from a file or file-like object.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filename_or_obj : str, Path, file-like or DataStore\n",
       "    Strings and Path objects are interpreted as a path to a netCDF file\n",
       "    or an OpenDAP URL and opened with python-netCDF4, unless the filename\n",
       "    ends with .gz, in which case the file is gunzipped and opened with\n",
       "    scipy.io.netcdf (only netCDF3 supported). Byte-strings or file-like\n",
       "    objects are opened by scipy.io.netcdf (netCDF3) or h5py (netCDF4/HDF).\n",
       "engine : {\"netcdf4\", \"scipy\", \"pydap\", \"h5netcdf\", \"pynio\", \"cfgrib\",         \"pseudonetcdf\", \"zarr\", None}, installed backend         or subclass of xarray.backends.BackendEntrypoint, optional\n",
       "    Engine to use when reading files. If not provided, the default engine\n",
       "    is chosen based on available dependencies, with a preference for\n",
       "    \"netcdf4\". A custom backend class (a subclass of ``BackendEntrypoint``)\n",
       "    can also be used.\n",
       "chunks : int, dict, 'auto' or None, optional\n",
       "    If chunks is provided, it is used to load the new dataset into dask\n",
       "    arrays. ``chunks=-1`` loads the dataset with dask using a single\n",
       "    chunk for all arrays. ``chunks={}`` loads the dataset with dask using\n",
       "    engine preferred chunks if exposed by the backend, otherwise with\n",
       "    a single chunk for all arrays.\n",
       "    ``chunks='auto'`` will use dask ``auto`` chunking taking into account the\n",
       "    engine preferred chunks. See dask chunking for more details.\n",
       "cache : bool, optional\n",
       "    If True, cache data loaded from the underlying datastore in memory as\n",
       "    NumPy arrays when accessed to avoid reading from the underlying data-\n",
       "    store multiple times. Defaults to True unless you specify the `chunks`\n",
       "    argument to use dask, in which case it defaults to False. Does not\n",
       "    change the behavior of coordinates corresponding to dimensions, which\n",
       "    always load their data from disk into a ``pandas.Index``.\n",
       "decode_cf : bool, optional\n",
       "    Whether to decode these variables, assuming they were saved according\n",
       "    to CF conventions.\n",
       "mask_and_scale : bool, optional\n",
       "    If True, replace array values equal to `_FillValue` with NA and scale\n",
       "    values according to the formula `original_values * scale_factor +\n",
       "    add_offset`, where `_FillValue`, `scale_factor` and `add_offset` are\n",
       "    taken from variable attributes (if they exist).  If the `_FillValue` or\n",
       "    `missing_value` attribute contains multiple values a warning will be\n",
       "    issued and all array values matching one of the multiple values will\n",
       "    be replaced by NA. mask_and_scale defaults to True except for the\n",
       "    pseudonetcdf backend. This keyword may not be supported by all the backends.\n",
       "decode_times : bool, optional\n",
       "    If True, decode times encoded in the standard NetCDF datetime format\n",
       "    into datetime objects. Otherwise, leave them encoded as numbers.\n",
       "    This keyword may not be supported by all the backends.\n",
       "decode_timedelta : bool, optional\n",
       "    If True, decode variables and coordinates with time units in\n",
       "    {\"days\", \"hours\", \"minutes\", \"seconds\", \"milliseconds\", \"microseconds\"}\n",
       "    into timedelta objects. If False, leave them encoded as numbers.\n",
       "    If None (default), assume the same value of decode_time.\n",
       "    This keyword may not be supported by all the backends.\n",
       "use_cftime: bool, optional\n",
       "    Only relevant if encoded dates come from a standard calendar\n",
       "    (e.g. \"gregorian\", \"proleptic_gregorian\", \"standard\", or not\n",
       "    specified).  If None (default), attempt to decode times to\n",
       "    ``np.datetime64[ns]`` objects; if this is not possible, decode times to\n",
       "    ``cftime.datetime`` objects. If True, always decode times to\n",
       "    ``cftime.datetime`` objects, regardless of whether or not they can be\n",
       "    represented using ``np.datetime64[ns]`` objects.  If False, always\n",
       "    decode times to ``np.datetime64[ns]`` objects; if this is not possible\n",
       "    raise an error. This keyword may not be supported by all the backends.\n",
       "concat_characters : bool, optional\n",
       "    If True, concatenate along the last dimension of character arrays to\n",
       "    form string arrays. Dimensions will only be concatenated over (and\n",
       "    removed) if they have no corresponding variable and if they are only\n",
       "    used as the last dimension of character arrays.\n",
       "    This keyword may not be supported by all the backends.\n",
       "decode_coords : bool or {\"coordinates\", \"all\"}, optional\n",
       "    Controls which variables are set as coordinate variables:\n",
       "\n",
       "    - \"coordinates\" or True: Set variables referred to in the\n",
       "      ``'coordinates'`` attribute of the datasets or individual variables\n",
       "      as coordinate variables.\n",
       "    - \"all\": Set variables referred to in  ``'grid_mapping'``, ``'bounds'`` and\n",
       "      other attributes as coordinate variables.\n",
       "drop_variables: str or iterable of str, optional\n",
       "    A variable or list of variables to exclude from being parsed from the\n",
       "    dataset. This may be useful to drop variables with problems or\n",
       "    inconsistent values.\n",
       "inline_array: bool, default: False\n",
       "    How to include the array in the dask task graph.\n",
       "    By default(``inline_array=False``) the array is included in a task by\n",
       "    itself, and each chunk refers to that task by its key. With\n",
       "    ``inline_array=True``, Dask will instead inline the array directly\n",
       "    in the values of the task graph. See :py:func:`dask.array.from_array`.\n",
       "backend_kwargs: dict\n",
       "    Additional keyword arguments passed on to the engine open function,\n",
       "    equivalent to `**kwargs`.\n",
       "**kwargs: dict\n",
       "    Additional keyword arguments passed on to the engine open function.\n",
       "    For example:\n",
       "\n",
       "    - 'group': path to the netCDF4 group in the given file to open given as\n",
       "      a str,supported by \"netcdf4\", \"h5netcdf\", \"zarr\".\n",
       "    - 'lock': resource lock to use when reading data from disk. Only\n",
       "      relevant when using dask or another form of parallelism. By default,\n",
       "      appropriate locks are chosen to safely read and write files with the\n",
       "      currently active dask scheduler. Supported by \"netcdf4\", \"h5netcdf\",\n",
       "      \"scipy\", \"pynio\", \"pseudonetcdf\", \"cfgrib\".\n",
       "\n",
       "    See engine open function for kwargs accepted by each specific engine.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "dataset : Dataset\n",
       "    The newly created dataset.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "``open_dataset`` opens the file with read-only access. When you modify\n",
       "values of a Dataset, even one linked to files on disk, only the in-memory\n",
       "copy you are manipulating in xarray is modified: the original file on disk\n",
       "is never touched.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "open_mfdataset\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/wwa/lib/python3.10/site-packages/xarray/backends/api.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?xr.open_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536cb0a-32a2-46fc-9b41-5430b81e9936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa]",
   "language": "python",
   "name": "conda-env-wwa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
